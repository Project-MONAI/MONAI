name: crons

on:
  schedule:
    - cron: "0 2 * * *"  # at 02:00 UTC

jobs:
  cron-gpu:
    if: github.repository == 'Project-MONAI/MONAI'
    container:
      image: nvcr.io/nvidia/pytorch:20.03-py3  # CUDA 10.2
      options: "--gpus all"
    runs-on: [self-hosted, linux, x64, common]
    strategy:
      matrix:
        pytorch-version: [1.5.0, 1.5.1, 1.6.0, latest]
    steps:
    - uses: actions/checkout@v2
    - name: Install the dependencies
      run: |
        which python
        python -m pip install --upgrade pip wheel
        python -m pip uninstall -y torch torchvision
        if [ ${{ matrix.pytorch-version }} == "latest" ]; then
          python -m pip install torch torchvision
        elif [ ${{ matrix.pytorch-version }} == "1.5.0" ]; then
          python -m pip install torch==1.5.0
          python -m pip install torchvision==0.6.0
        elif [ ${{ matrix.pytorch-version }} == "1.5.1" ]; then
          python -m pip install torch==1.5.1
          python -m pip install torchvision==0.6.1
        elif [ ${{ matrix.pytorch-version }} == "1.6.0" ]; then
          python -m pip install torch==1.6.0
          python -m pip install torchvision==0.7.0
        fi
        python -m pip install -r requirements-dev.txt
        python -m pip list
    - name: Run tests report coverage
      run: |
        export LAUNCH_DELAY=$[ $RANDOM % 16 * 60 ]
        echo "Sleep $LAUNCH_DELAY"
        sleep $LAUNCH_DELAY
        nvidia-smi
        export CUDA_VISIBLE_DEVICES=$(python -m tests.utils)
        echo $CUDA_VISIBLE_DEVICES
        python -c "import torch; print(torch.__version__); print('{} of GPUs available'.format(torch.cuda.device_count()))"
        python -c 'import torch; print(torch.rand(5,3, device=torch.device("cuda:0")))'
        BUILD_MONAI=1 ./runtests.sh --coverage
        coverage xml
    - name: Upload coverage
      uses: codecov/codecov-action@v1
      with:
        fail_ci_if_error: false
        file: ./coverage.xml

  cron-docker:
    if: github.repository == 'Project-MONAI/MONAI'
    container:
      image: docker://projectmonai/monai:latest
      options: "--gpus all"
    runs-on: [self-hosted, linux, x64, common]
    steps:
    - name: Run tests report coverage
      run: |
        cd /opt/monai
        nvidia-smi
        export CUDA_VISIBLE_DEVICES=$(python -m tests.utils)
        echo $CUDA_VISIBLE_DEVICES
        python -c "import torch; print(torch.__version__); print('{} of GPUs available'.format(torch.cuda.device_count()))"
        python -c 'import torch; print(torch.rand(5,3, device=torch.device("cuda:0")))'
        ngc --version
        BUILD_MONAI=1 ./runtests.sh --coverage --pytype
        coverage xml
    - name: Upload coverage
      uses: codecov/codecov-action@v1
      with:
        fail_ci_if_error: false
        file: ./coverage.xml
